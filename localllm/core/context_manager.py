"""Smart context management system"""

import os
import time
import hashlib
import re
from pathlib import Path
from typing import List, Dict, Optional, TYPE_CHECKING

if TYPE_CHECKING:
    from ..llm.clients import LLMClient
    from .project_dna import ProjectDNA

from .config import get_config_manager, ContextConfig
from .i18n import t

try:
    from rich.console import Console
    console = Console()
except ImportError:
    class Console:
        def print(self, *args, **kwargs):
            print(*args)
    console = Console()

class SmartContextManager:
    """é©æ–°çš„ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, max_tokens: Optional[int] = None, config: Optional[ContextConfig] = None):
        # è¨­å®šã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆ
        self.config_manager = get_config_manager()
        self.config = config or self.config_manager.get_context_config()
        
        # max_tokensã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯å¼•æ•°ã‹ã‚‰å–å¾—
        self.max_tokens = max_tokens or self.config.max_tokens
        
        # æ—¢å­˜ã®å±æ€§
        self.file_cache = {}
        self.relevance_scores = {}
        self.context_history = []
        self.compressed_contexts = {}
        
        # è¨­å®šã«åŸºã¥ãå‹•çš„ãªé–¾å€¤
        self.compression_threshold = self.max_tokens * self.config.compression_threshold
        self.warning_threshold = self.max_tokens * self.config.warning_threshold
        
        # æ–°ã—ã„ç›£è¦–æ©Ÿèƒ½
        self.current_tokens = 0
        self.token_usage_history = []
        self.last_warning_time = 0
        
    def calculate_relevance(self, file_path: str, query: str, project_dna: 'ProjectDNA') -> float:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®é–¢é€£åº¦ã‚’è¨ˆç®—ï¼ˆé©æ–°çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼‰"""
        score = 0.0
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã®é–¢é€£åº¦
        if any(keyword.lower() in file_path.lower() for keyword in query.split()):
            score += 0.3
            
        # æ‹¡å¼µå­ã®é–¢é€£åº¦
        ext = Path(file_path).suffix
        if ext in project_dna.file_patterns:
            score += 0.2
            
        # æœ€è¿‘ã®å¤‰æ›´å±¥æ­´
        try:
            stat = os.stat(file_path)
            age_days = (time.time() - stat.st_mtime) / (24 * 3600)
            if age_days < 1:
                score += 0.3
            elif age_days < 7:
                score += 0.2
        except:
            pass
            
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºï¼ˆé©åº¦ãªã‚µã‚¤ã‚ºã‚’å„ªå…ˆï¼‰
        try:
            size = os.path.getsize(file_path)
            if 100 < size < 10000:  # 100Bã€œ10KB
                score += 0.2
        except:
            pass
            
        return min(score, 1.0)
    
    def select_optimal_context(self, query: str, project_dna: 'ProjectDNA', 
                             available_files: List[str]) -> List[str]:
        """æœ€é©ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è‡ªå‹•é¸æŠ"""
        scored_files = []
        
        for file_path in available_files:
            relevance = self.calculate_relevance(file_path, query, project_dna)
            scored_files.append((file_path, relevance))
        
        # é–¢é€£åº¦ã§ã‚½ãƒ¼ãƒˆã—ã€ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™å†…ã§é¸æŠ
        scored_files.sort(key=lambda x: x[1], reverse=True)
        
        selected_files = []
        total_tokens = len(query.split()) * 2  # ã‚¯ã‚¨ãƒªã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ¨å®š
        
        for file_path, score in scored_files:
            if score < 0.1:  # é–¢é€£åº¦ãŒä½ã™ãã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                continue
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    file_tokens = len(content.split())
                    
                if total_tokens + file_tokens < self.max_tokens * 0.8:  # 80%ã¾ã§ä½¿ç”¨
                    selected_files.append(file_path)
                    total_tokens += file_tokens
                else:
                    break
            except:
                continue
                
        return selected_files
    
    async def compress_context(self, context: str, llm_client: 'LLMClient', summary_length: str = "medium") -> str:
        """LLMã‚’ä½¿ç”¨ã—ã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åœ§ç¸®"""
        if len(context.split()) < self.compression_threshold * 0.5:
            return context  # åœ§ç¸®ä¸è¦
        
        # åœ§ç¸®ãƒ¬ãƒ™ãƒ«è¨­å®š
        compression_levels = {
            "brief": "Summarize this in 2-3 sentences, focusing on key points only.",
            "medium": "Summarize this in 1-2 paragraphs, preserving important details and context.",
            "detailed": "Create a comprehensive summary that retains most important information while reducing length by 50%."
        }
        
        compression_prompt = compression_levels.get(summary_length, compression_levels["medium"])
        
        system_prompt = f"""You are a context compression expert. Your task is to compress the given text while preserving all essential information for a coding assistant.

{compression_prompt}

Focus on:
- Key technical details
- Important file names and paths
- Error messages and their solutions
- Code snippets and modifications
- Process steps and outcomes

Remove:
- Verbose explanations
- Redundant information
- Unnecessary background context
"""
        
        try:
            compressed = await llm_client.generate(
                f"Please compress this context:\n\n{context}",
                system_prompt,
                stream=False
            )
            
            # åœ§ç¸®çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
            context_hash = hashlib.md5(context.encode()).hexdigest()
            self.compressed_contexts[context_hash] = {
                'original_length': len(context),
                'compressed_length': len(compressed),
                'compressed_content': compressed,
                'compression_ratio': len(compressed) / len(context),
                'timestamp': time.time()
            }
            
            return compressed
            
        except Exception as e:
            console.print(f"[yellow]Context compression failed: {e}. Using original.[/yellow]")
            return context
    
    def get_context_summary(self) -> str:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåœ§ç¸®ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        if not self.compressed_contexts:
            return "No context compression performed yet."
        
        total_original = sum(c['original_length'] for c in self.compressed_contexts.values())
        total_compressed = sum(c['compressed_length'] for c in self.compressed_contexts.values())
        avg_ratio = sum(c['compression_ratio'] for c in self.compressed_contexts.values()) / len(self.compressed_contexts)
        
        return f"Context Compression Stats: {len(self.compressed_contexts)} compressions, avg ratio: {avg_ratio:.2f}, saved: {total_original - total_compressed} chars"
    
    def estimate_tokens(self, text: str) -> int:
        """ã‚ˆã‚Šæ­£ç¢ºãªãƒˆãƒ¼ã‚¯ãƒ³æ•°æ¨å®š"""
        if not text:
            return 0
        
        # æ—¥æœ¬èªã¨è‹±èªã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°æ¨å®šã®æ”¹å–„
        # æ—¥æœ¬èªï¼šæ–‡å­—æ•° * 0.75ã€è‹±èªï¼šå˜èªæ•° * 1.3
        english_chars = len(re.findall(r'[a-zA-Z]', text))
        japanese_chars = len(text) - english_chars
        
        # å˜èªæ•°ãƒ™ãƒ¼ã‚¹ã®è¨ˆç®—
        words = len(text.split())
        
        # ã‚ˆã‚Šæ­£ç¢ºãªæ¨å®šï¼š
        # - è‹±èªå˜èªã¯å¹³å‡1.3ãƒˆãƒ¼ã‚¯ãƒ³
        # - æ—¥æœ¬èªæ–‡å­—ã¯å¹³å‡0.75ãƒˆãƒ¼ã‚¯ãƒ³
        # - ã‚³ãƒ¼ãƒ‰éƒ¨åˆ†ã¯å˜èªæ•°ã®1.5å€
        
        if english_chars > japanese_chars:
            # ä¸»ã«è‹±èªãƒ»ã‚³ãƒ¼ãƒ‰
            estimated = words * 1.3
        else:
            # ä¸»ã«æ—¥æœ¬èª
            estimated = japanese_chars * 0.75 + words * 0.5
        
        # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’æ¤œå‡ºã—ã¦ãƒœãƒ¼ãƒŠã‚¹
        if '```' in text or '    ' in text:  # ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã‚„ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯
            estimated *= 1.2
        
        return int(estimated)
    
    def update_token_count(self, context: str):
        """ç¾åœ¨ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ›´æ–°"""
        self.current_tokens = self.estimate_tokens(context)
        self.token_usage_history.append({
            'timestamp': time.time(),
            'tokens': self.current_tokens,
            'ratio': self.current_tokens / self.max_tokens
        })
        
        # å±¥æ­´ã®åˆ¶é™ï¼ˆæœ€æ–°100ä»¶ï¼‰
        if len(self.token_usage_history) > 100:
            self.token_usage_history = self.token_usage_history[-100:]
    
    def check_context_status(self, context: str, show_warnings: bool = True) -> Dict[str, any]:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆçŠ¶æ³ã‚’ãƒã‚§ãƒƒã‚¯"""
        self.update_token_count(context)
        
        usage_ratio = self.current_tokens / self.max_tokens
        status = {
            'current_tokens': self.current_tokens,
            'max_tokens': self.max_tokens,
            'usage_ratio': usage_ratio,
            'needs_compression': self.config_manager.should_compress(self.current_tokens),
            'needs_warning': self.config_manager.should_warn(self.current_tokens),
            'status': 'normal'
        }
        
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¤å®š
        if usage_ratio >= self.config.warning_threshold:
            status['status'] = 'critical'
        elif usage_ratio >= self.config.compression_threshold:
            status['status'] = 'warning'
        
        # è­¦å‘Šè¡¨ç¤º
        if show_warnings and status['needs_warning']:
            self._show_context_warning(status)
        
        return status
    
    def _show_context_warning(self, status: Dict[str, any]):
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè­¦å‘Šã‚’è¡¨ç¤º"""
        current_time = time.time()
        # 1åˆ†ä»¥å†…ã®é‡è¤‡è­¦å‘Šã‚’é¿ã‘ã‚‹
        if current_time - self.last_warning_time < 60:
            return
        
        self.last_warning_time = current_time
        usage_percent = status['usage_ratio'] * 100
        
        if status['status'] == 'critical':
            msg = t('context_critical', usage=usage_percent)
            console.print(f"âš ï¸ [red]{msg}[/red]")
            console.print(f"[yellow]{t('context_critical_advice')}[/yellow]")
        elif status['status'] == 'warning':
            msg = t('context_warning', usage=usage_percent)
            console.print(f"âš ï¸ [yellow]{msg}[/yellow]")
    
    def get_optimal_compression_strategy(self, context: str) -> str:
        """æœ€é©ãªåœ§ç¸®æˆ¦ç•¥ã‚’æ±ºå®š"""
        status = self.check_context_status(context, show_warnings=False)
        
        if status['usage_ratio'] >= 0.9:
            return "brief"  # ç·Šæ€¥åœ§ç¸®
        elif status['usage_ratio'] >= 0.8:
            return "medium"  # æ¨™æº–åœ§ç¸®
        else:
            return "detailed"  # è©³ç´°ä¿æŒ
    
    def auto_manage_context(self, context: str, llm_client: 'LLMClient') -> str:
        """è‡ªå‹•ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†"""
        status = self.check_context_status(context)
        
        if not status['needs_compression']:
            return context
        
        if not self.config.auto_compression:
            # è‡ªå‹•åœ§ç¸®ãŒç„¡åŠ¹ã®å ´åˆã¯è­¦å‘Šã®ã¿
            return context
        
        # è‡ªå‹•åœ§ç¸®å®Ÿè¡Œ
        compression_strategy = self.get_optimal_compression_strategy(context)
        msg = t('auto_compressing', strategy=compression_strategy)
        console.print(f"ğŸ—œï¸ [cyan]{msg}[/cyan]")
        
        return self.compress_context(context, llm_client, compression_strategy)
    
    def get_context_metrics(self) -> Dict[str, any]:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—"""
        if not self.token_usage_history:
            return {
                'current_tokens': 0,
                'max_tokens': self.max_tokens,
                'usage_ratio': 0.0,
                'avg_usage': 0.0,
                'peak_usage': 0.0
            }
        
        recent_usage = [entry['ratio'] for entry in self.token_usage_history[-10:]]
        
        return {
            'current_tokens': self.current_tokens,
            'max_tokens': self.max_tokens,
            'usage_ratio': self.current_tokens / self.max_tokens,
            'avg_usage': sum(recent_usage) / len(recent_usage),
            'peak_usage': max(entry['ratio'] for entry in self.token_usage_history),
            'compression_threshold': self.config.compression_threshold,
            'warning_threshold': self.config.warning_threshold,
            'auto_compression': self.config.auto_compression
        }
    
    def optimize_for_model(self, model_name: str):
        """ãƒ¢ãƒ‡ãƒ«ã«å¿œã˜ãŸæœ€é©åŒ–"""
        self.config_manager.auto_adjust_for_model(model_name)
        new_max = self.config_manager.get_max_tokens()
        
        if new_max != self.max_tokens:
            msg = t('context_optimized', model=model_name, tokens=new_max)
            console.print(f"ğŸ“Š [green]{msg}[/green]")
            self.max_tokens = new_max
            self.compression_threshold = new_max * self.config.compression_threshold
            self.warning_threshold = new_max * self.config.warning_threshold