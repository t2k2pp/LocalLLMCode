"""Project analysis system"""

import json
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any

try:
    from rich.console import Console
    from rich.progress import Progress, SpinnerColumn, TextColumn
    console = Console()
except ImportError:
    class Console:
        def print(self, *args, **kwargs):
            print(*args)
    console = Console()
    
    class Progress:
        def __init__(self, *args, **kwargs):
            pass
        def __enter__(self):
            return self
        def __exit__(self, *args):
            pass
        def add_task(self, *args, **kwargs):
            return 1
        def update(self, *args, **kwargs):
            pass

from ..core.project_dna import ProjectDNA

class ProjectAnalyzer:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆDNAåˆ†æžã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.ignore_patterns = {
            '.git', '__pycache__', 'node_modules', '.venv', 'venv',
            'dist', 'build', '.DS_Store', '*.pyc', '*.log'
        }
    
    def analyze_project(self, root_path: Path) -> ProjectDNA:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å®Œå…¨ãªDNAè§£æž"""
        console.print("ðŸ§¬ [bold cyan]Analyzing Project DNA...[/bold cyan]")
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            task = progress.add_task("Scanning project structure...", total=None)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åŽé›†
            all_files = list(self._scan_files(root_path))
            progress.update(task, description="Analyzing languages...")
            
            # è¨€èªžåˆ†æž
            language = self._detect_primary_language(all_files)
            progress.update(task, description="Detecting frameworks...")
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯æ¤œå‡º
            frameworks = self._detect_frameworks(all_files, root_path)
            progress.update(task, description="Analyzing architecture...")
            
            # ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‘ã‚¿ãƒ¼ãƒ³
            patterns = self._detect_architecture_patterns(all_files, root_path)
            progress.update(task, description="Learning coding style...")
            
            # ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¹ã‚¿ã‚¤ãƒ«å­¦ç¿’
            coding_style = self._learn_coding_style(all_files)
            progress.update(task, description="Building dependency graph...")
            
            # ä¾å­˜é–¢ä¿‚ã‚°ãƒ©ãƒ•
            dependency_graph = self._build_dependency_graph(all_files, root_path)
            progress.update(task, description="Calculating complexity...")
            
            # è¤‡é›‘åº¦è¨ˆç®—
            complexity = self._calculate_complexity(all_files)
            
            progress.update(task, description="Complete!", completed=True)
        
        dna = ProjectDNA(
            language=language,
            frameworks=frameworks,
            architecture_patterns=patterns,
            coding_style=coding_style,
            dependency_graph=dependency_graph,
            file_patterns=self._extract_file_patterns(all_files),
            common_operations=self._extract_common_operations(all_files),
            last_updated=datetime.now().isoformat(),
            complexity_score=complexity
        )
        
        # DNAã‚’ä¿å­˜
        self._save_dna(root_path, dna)
        
        return dna
    
    def _scan_files(self, root_path: Path):
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒ£ãƒ³"""
        for file_path in root_path.rglob('*'):
            if file_path.is_file() and not self._should_ignore(file_path):
                yield file_path
    
    def _should_ignore(self, file_path: Path) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç„¡è¦–ã™ã¹ãã‹ãƒã‚§ãƒƒã‚¯"""
        path_str = str(file_path)
        return any(pattern in path_str for pattern in self.ignore_patterns)
    
    def _detect_primary_language(self, files: List[Path]) -> str:
        """ä¸»è¦è¨€èªžã‚’æ¤œå‡º"""
        extensions = {}
        for file_path in files:
            ext = file_path.suffix.lower()
            if ext:
                extensions[ext] = extensions.get(ext, 0) + 1
        
        if not extensions:
            return "unknown"
        
        # æœ€ã‚‚å¤šã„æ‹¡å¼µå­ã‹ã‚‰è¨€èªžã‚’æŽ¨å®š
        primary_ext = max(extensions, key=extensions.get)
        
        lang_map = {
            '.py': 'Python', '.js': 'JavaScript', '.ts': 'TypeScript',
            '.java': 'Java', '.cpp': 'C++', '.c': 'C', '.cs': 'C#',
            '.go': 'Go', '.rs': 'Rust', '.rb': 'Ruby', '.php': 'PHP',
            '.jsx': 'React', '.tsx': 'TypeScript React', '.vue': 'Vue.js'
        }
        
        return lang_map.get(primary_ext, 'unknown')
    
    def _detect_frameworks(self, files: List[Path], root_path: Path) -> List[str]:
        """ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æ¤œå‡º"""
        frameworks = []
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã®æ¤œå‡º
        config_files = {
            'package.json': self._detect_js_frameworks,
            'requirements.txt': self._detect_python_frameworks,
            'Pipfile': self._detect_python_frameworks,
            'pyproject.toml': self._detect_python_frameworks,
            'pom.xml': lambda x: ['Maven', 'Spring'],
            'build.gradle': lambda x: ['Gradle', 'Spring'],
            'Cargo.toml': lambda x: ['Rust'],
        }
        
        for file_path in files:
            if file_path.name in config_files:
                try:
                    detected = config_files[file_path.name](file_path)
                    if isinstance(detected, list):
                        frameworks.extend(detected)
                    else:
                        frameworks.extend(detected())
                except:
                    pass
        
        return list(set(frameworks))
    
    def _detect_js_frameworks(self, package_json_path: Path) -> List[str]:
        """package.jsonã‹ã‚‰JavaScriptãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æ¤œå‡º"""
        try:
            with open(package_json_path, 'r') as f:
                data = json.load(f)
            
            frameworks = []
            deps = {**data.get('dependencies', {}), **data.get('devDependencies', {})}
            
            framework_map = {
                'react': 'React', 'vue': 'Vue.js', 'angular': 'Angular',
                'next': 'Next.js', 'nuxt': 'Nuxt.js', 'express': 'Express.js',
                'fastify': 'Fastify', 'nest': 'NestJS', 'svelte': 'Svelte'
            }
            
            for dep in deps:
                for fw_key, fw_name in framework_map.items():
                    if fw_key in dep.lower():
                        frameworks.append(fw_name)
            
            return frameworks
        except:
            return []
    
    def _detect_python_frameworks(self, requirements_path: Path) -> List[str]:
        """Pythonãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æ¤œå‡º"""
        try:
            with open(requirements_path, 'r') as f:
                content = f.read().lower()
            
            frameworks = []
            framework_map = {
                'django': 'Django', 'flask': 'Flask', 'fastapi': 'FastAPI',
                'tornado': 'Tornado', 'pyramid': 'Pyramid', 'sanic': 'Sanic',
                'starlette': 'Starlette', 'quart': 'Quart'
            }
            
            for fw_key, fw_name in framework_map.items():
                if fw_key in content:
                    frameworks.append(fw_name)
            
            return frameworks
        except:
            return []
    
    def _detect_architecture_patterns(self, files: List[Path], root_path: Path) -> List[str]:
        """ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º"""
        patterns = []
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŽ¨å®š
        dirs = {f.parent.name.lower() for f in files if f.parent != root_path}
        
        # MVC ãƒ‘ã‚¿ãƒ¼ãƒ³
        if {'models', 'views', 'controllers'}.issubset(dirs):
            patterns.append('MVC')
        
        # Clean Architecture
        if {'domain', 'infrastructure', 'application'}.issubset(dirs):
            patterns.append('Clean Architecture')
        
        # Microservices
        if {'services', 'api', 'gateway'}.intersection(dirs):
            patterns.append('Microservices')
        
        # Component-based
        if {'components', 'containers', 'hooks'}.intersection(dirs):
            patterns.append('Component-based')
        
        return patterns
    
    def _learn_coding_style(self, files: List[Path]) -> Dict[str, Any]:
        """ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¹ã‚¿ã‚¤ãƒ«ã‚’å­¦ç¿’"""
        style = {
            'indentation': 'spaces',
            'indent_size': 4,
            'max_line_length': 80,
            'naming_convention': 'snake_case',
            'documentation_style': 'docstring'
        }
        
        # å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å­¦ç¿’
        try:
            python_files = [f for f in files if f.suffix == '.py']
            if python_files:
                sample_file = python_files[0]
                with open(sample_file, 'r') as f:
                    content = f.read()
                
                # ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆåˆ†æž
                lines = content.split('\n')
                indented_lines = [line for line in lines if line.startswith((' ', '\t'))]
                
                if indented_lines:
                    first_indent = indented_lines[0]
                    if first_indent.startswith('\t'):
                        style['indentation'] = 'tabs'
                    else:
                        spaces = len(first_indent) - len(first_indent.lstrip())
                        style['indent_size'] = spaces
        except:
            pass
        
        return style
    
    def _build_dependency_graph(self, files: List[Path], root_path: Path) -> Dict[str, List[str]]:
        """ä¾å­˜é–¢ä¿‚ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰"""
        graph = {}
        
        for file_path in files:
            if file_path.suffix in ['.py', '.js', '.ts', '.jsx', '.tsx']:
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    imports = self._extract_imports(content, file_path.suffix)
                    relative_path = str(file_path.relative_to(root_path))
                    graph[relative_path] = imports
                except:
                    continue
        
        return graph
    
    def _extract_imports(self, content: str, extension: str) -> List[str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰importæ–‡ã‚’æŠ½å‡º"""
        imports = []
        
        if extension == '.py':
            # Python imports
            import_patterns = [
                r'from\s+(\S+)\s+import',
                r'import\s+(\S+)'
            ]
        elif extension in ['.js', '.ts', '.jsx', '.tsx']:
            # JavaScript/TypeScript imports
            import_patterns = [
                r'import.*from\s+["\']([^"\']+)["\']',
                r'import\s+["\']([^"\']+)["\']'
            ]
        else:
            return imports
        
        for pattern in import_patterns:
            matches = re.findall(pattern, content)
            imports.extend(matches)
        
        return imports
    
    def _extract_file_patterns(self, files: List[Path]) -> Dict[str, str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º"""
        patterns = {}
        
        for file_path in files:
            ext = file_path.suffix
            if ext:
                patterns[ext] = patterns.get(ext, '') + f"{file_path.name} "
        
        return patterns
    
    def _extract_common_operations(self, files: List[Path]) -> List[str]:
        """ã‚ˆãä½¿ã‚ã‚Œã‚‹æ“ä½œã‚’æŠ½å‡º"""
        operations = [
            "add new feature", "fix bug", "refactor code", "update dependencies",
            "write tests", "improve performance", "add documentation"
        ]
        return operations
    
    def _calculate_complexity(self, files: List[Path]) -> float:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®è¤‡é›‘åº¦ã‚’è¨ˆç®—"""
        total_files = len(files)
        total_lines = 0
        
        for file_path in files[:50]:  # æœ€åˆã®50ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    total_lines += len(f.readlines())
            except:
                continue
        
        # è¤‡é›‘åº¦è¨ˆç®—ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«æ•°ã¨ã‚³ãƒ¼ãƒ‰è¡Œæ•°ã‚’åŸºæº–ï¼‰
        complexity = min(10.0, (total_files / 100 + total_lines / 10000) * 5)
        return complexity
    
    def _save_dna(self, root_path: Path, dna: ProjectDNA):
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆDNAã‚’ä¿å­˜"""
        dna_file = root_path / 'LOCALLLM.md'
        
        content = f"""# LocalLLM Code Project Memory

Generated: {dna.last_updated}

## Project DNA

{dna.to_context()}

## Project Structure
```
{self._generate_tree_structure(root_path)}
```

## Learning Notes
- This project follows {dna.language} conventions
- Architecture patterns: {', '.join(dna.architecture_patterns)}
- Complexity level: {dna.complexity_score:.1f}/10.0

## Common Operations
{chr(10).join(f"- {op}" for op in dna.common_operations)}

---
*This file is automatically generated and updated by LocalLLM Code*
"""
        
        with open(dna_file, 'w', encoding='utf-8') as f:
            f.write(content)
    
    def _generate_tree_structure(self, root_path: Path, max_depth: int = 3) -> str:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã‚’æ–‡å­—åˆ—ã¨ã—ã¦ç”Ÿæˆ"""
        def build_tree(path: Path, prefix: str = "", depth: int = 0) -> str:
            if depth >= max_depth:
                return ""
            
            items = []
            try:
                children = sorted(path.iterdir(), key=lambda x: (x.is_file(), x.name))
                for i, child in enumerate(children[:10]):  # æœ€å¤§10é …ç›®
                    if self._should_ignore(child):
                        continue
                    
                    is_last = i == len(children) - 1
                    current_prefix = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
                    next_prefix = "    " if is_last else "â”‚   "
                    
                    items.append(f"{prefix}{current_prefix}{child.name}")
                    
                    if child.is_dir() and depth < max_depth - 1:
                        items.append(build_tree(child, prefix + next_prefix, depth + 1))
            except PermissionError:
                pass
            
            return "\n".join(filter(None, items))
        
        return build_tree(root_path)